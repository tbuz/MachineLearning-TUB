%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage[version=3]{mhchem} % Package for chemical equation typesetting
\usepackage{siunitx} % Provides the \SI{}{} and \si{} command for typesetting SI units
\usepackage{graphicx} % Required for the inclusion of images
\usepackage{natbib} % Required to change bibliography style to APA
\usepackage{amsmath} % Required for some math elements 
\usepackage{amssymb}
\usepackage{amsfonts}

\setlength\parindent{0pt} % Removes all indentation from paragraphs

\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

%\usepackage{times} % Uncomment to use the Times New Roman font

\newcommand{\PartDiv}[1]{\frac{\partial}{\partial #1}}
\newcommand{\F}[0]{\mathbb{F}}
\newcommand{\N}[0]{\mathbb{N}}
\newcommand{\Z}[0]{\mathbb{Z}}
\newcommand{\Q}[0]{\mathbb{Q}}
\newcommand{\R}[0]{\mathbb{R}}
\newcommand{\C}[0]{\mathbb{C}}
\newcommand{\B}[0]{\mathbb{B}}
\newcommand{\im}[0]{\mathit{i}}
\newcommand{\uber}[2]{{{#1} \choose {#2}}}
\newcommand{\vect}[1]{\begin{pmatrix}#1\end{pmatrix}}
\newcommand{\norm}[1]{\left\lvert #1 \right\rvert}
\allowdisplaybreaks


%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Machine Learning 1 \\ Exercise 8} % Title

\author{Group: BSSBCH} % Author name

\date{\today} % Date for the report


\begin{document}

\maketitle % Insert the title, author and date
\noindent\rule[0.5ex]{\linewidth}{1pt}
Matthias Bigalke, 339547, maku@win.tu-berlin.de \\
Tolga Buz, 346836, buz\_tolga@yahoo.de \\
Alejandro Hernandez, 395678, alejandrohernandezmunuera@gmail.com \\
Aitor Palacios Cuesta, 396276, aitor.palacioscuesta@campus.tu-berlin.de \\
Christof Schubert, 344450, christof.schubert@campus.tu-berlin.de \\
Daniel Steinhaus, 342563, dany.steinhaus@googlemail.com\\
\noindent\rule[0.5ex]{\linewidth}{1pt}
% If you wish to include an abstract, uncomment the lines below
% \begin{abstract}
% Abstract text
% \end{abstract}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section*{Exercise 1}

\subsection*{Kernology}

\subsection*{a)}

\subsubsection*{i}

Show that
$k(x,x') = a \ \ \ \ \ a \in \mathbb{R}^+$ is a Mercer kernel:\\

\begin{align}
k(x_i,x_j) &= \sum_{i=1}^n \sum_{j=1}^n c_i c_j k(x_i,x_j) \\
&= \sum_{i=1}^n \sum_{j=1}^n c_i c_j a \\ 
&= a \sum_{i=1}^n c_i \sum_{j=1}^n c_j \\ 
&= a (\sum_{i=1}^n c_i) (\sum_{j=1}^n c_j) \\ 
&= a (\sum_{i=1}^n c_i)^2 \geq 0
\end{align}



\subsubsection*{ii}
Show that
$k(x,x') = \langle x,x' \rangle$ is a Mercer kernel:\\
\begin{align}
k(x_i,x_j) &=\sum_{i=1}^n \sum_{j=1}^n c_i c_j k(x_i,x_j) \\
&= \sum_{i=1}^n \sum_{j=1}^n c_i c_j \langle x_i,x_j \rangle \\
&= \sum_{i=1}^n \sum_{j=1}^n c_i c_j \  \vec{x_i}^T \cdot \vec{x_j}  \\
&= (\sum_{i=1}^n c_i \vec{x_i})^T (\sum_{j=1}^n c_j \vec{x_j})  \\
&= \vec{v}^T \vec{v} = || \vec{v} ||^2 \geq 0
\end{align}

\subsubsection*{iii}
Show that $
k(x,x') = f(x)\cdot f(x')$, where $f:\mathbb{R}^d~\rightarrow~\mathbb{R}$ is an arbitrary continuous function, is a Mercer kernel:\\
\begin{align}
k(x_i,x_j) &=\sum_{i=1}^n \sum_{j=1}^n c_i c_j k(x_i,x_j) \\
&= \sum_{i=1}^n \sum_{j=1}^n c_i c_j f(x_i) \cdot f(x_j) \\
&= (\sum_{i=1}^n c_i f(x_i))(\sum_{j=1}^n c_j f(x_j)) \\
&= (\sum_{i=1}^n c_i f(x_i))^2 \geq 0 \\
\end{align}


\subsection*{b)}

\subsubsection*{i}
Given $k_1$ and $k_2$ are Mercer kernels, show that:
\begin{equation}
    k(x, x') = k_1(x, x') + k_2(x, x')
\end{equation}
is a Mercer kernel.

\begin{align}
    \sum_{i=1}^d \sum_{j=1}^d k(x_i, x_j') &= k_1(x, x') + k_2(x, x') \\
    &= \sum_{i=1}^d \sum_{j=1}^d (k_1(x_i, x_j') + k_2(x_i, x_j'))\\
    &= \sum_{i=1}^d \sum_{j=1}^d k_1(x_i, x_j') + \sum_{i=1}^d \sum_{j=1}^d  k_2(x_i, x_j')
\end{align}
As both terms are are non-negative (Mercer kernels), the sums is also non-negative.
\hfill $\square$
\subsubsection*{ii}

Given $k_1$ and $k_2$ are Mercer kernels, show that:
\begin{equation}
    k(x, x') = k_1(x, x') \cdot k_2(x, x')
\end{equation}
is a Mercer kernel.


From the \emph{representer theorem}, we know that every kernel has a corresponding
scalar product.
Let $\phi : \R^d \mapsto \R^a $ be the feature maps such that $k_1(x, x') = \langle{}\phi(x),\phi(x')\rangle{}$ and
for $k_2$ let  $\psi : \R^d \mapsto \R^b$ be such that $k_2(x, x') = \langle{}\psi(x),\psi(x')\rangle{}$.

\begin{align}
    k(x, x') = &k_1(x, x') \cdot k_2(x, x')\\
    = & \langle{}\phi(x), \phi(x')\rangle{} \cdot \langle{}\psi(x), \psi(x')\rangle{}\\
    = & \phi(x)^T \phi(x') \cdot \psi(x)^T \psi(x')\\
    = & \sum_{i=1}^a \phi_i(x) \phi_i(x') \cdot \sum_{j=1}^b \psi_j(x) \psi_j(x')\\
    = & \sum_{i=1}^a \sum_{j=1}^b \phi_i(x) \phi_i(x') \cdot  \psi_j(x) \psi_j(x')\\
    = & \sum_{i=1}^a \sum_{j=1}^b \phi_i(x)  \psi_j(x) \phi_i(x') \psi_j(x')
\end{align}
Now we define another feature maps
$\chi(x) : \R^d \mapsto \R^{a \times b}$ to be $\chi(x) = \phi(x)^T \psi(x)$.
Note that $\chi_{ij}(x) = \phi_i(x) \psi_j(x)$.
\begin{align}
    = & \sum_{i=1}^a \sum_{j=1}^b \chi_{ij}(x)  \chi_{ij}(x') \\
    = & \chi(x)^T  \chi(x')
\end{align}
The product of two Mercer kernels can be rewritten as a scalar product of
the feature map $\chi$. Therefore the product must also be a Mercer kernel.
\hfill $\square$

\subsection*{c)}

Show that $ k(x, x') = (\langle{}x, x'\rangle{} + \nu)^l$ is a Mercer kernel, where $\nu \in \R_+$.

We can rewrite $k(x, x')$ as:

\begin{align}
    & k_\nu(x, x') = \nu \\
    & k_s(x, x') = \langle{}x, x'\rangle{} \\
    & k_+(x, x') = k_s(x, x') + k_\nu(x, x') \\
    & k(x, x') = \prod^l k_+(x, x')
\end{align}
Therefore, it $k$ is also a Mercer kernel. \hfill $\square$
\\


\subsection*{d)}
\begin{gather*}
k(x,x') = \exp{}(- \frac{||x-x'||^2}{2\sigma^2}) \\
= \exp{}(-\frac{||x||^2 - 2\langle{}x',x\rangle{} + ||x'||^2}{2\sigma^2}) \\
= \exp{}(-\frac{||x||^2}{2\sigma^2}) \cdot \exp{}(-\frac{||x'||^2}{2\sigma^2}) \cdot \exp{}(\frac{2\langle{}x',x\rangle{}}{2\sigma^2}) \\ 
\end{gather*}
Notice $\exp{}(-\frac{||x||^2}{2\sigma^2}) \cdot \exp{}(-\frac{||x'||^2}{2\sigma^2}) = f(x)\cdot f(x')$ and $\frac{2\langle{}x',x\rangle{}}{2\sigma^2}$ are Mercer kernels (from a,b,c). Now it is left to show that $\exp{}(k(x,x'))$ is a Mercer kernel if k is a Mercer kernel.
\begin{gather*}
\exp{}(k(x,x')) = \lim\limits_{i \rightarrow \infty}{(1 + k(x,x') + \frac{k(x,x')^2}{2} + \frac{k(x,x')^3}{6} + ... + \frac{k(x,x')^i}{i!})}
\end{gather*}
From a),b),c) we know this must also be a Mercer kernel and hence our Gaussian kernel is a Mercer kernel. 



\section*{Exercise 2}

\subsection*{The Feature Map}

\subsection*{a)}
Show:
\begin{equation}
    \langle{}\phi(x), \phi(y)\rangle{}~= \left(\sum_{i=1}^2 x_i y_i \right)^2
\end{equation}
\begin{align}
    \left(\sum_{i=1}^2 x_i y_i \right)^2 &= \left(x_1 y_1 + x_2 y_2 \right)^2 = \\
    & = x_1^2 y_1^2 + 2 x_1 y_1 x_2 y_2 + x_2^2 y_2^2  \\
\end{align}
Using the feature maps we get:
\begin{align}
    \langle{}\phi(x), \phi(y)\rangle{}~ &= \langle{}
        \begin{pmatrix}x_1^2 \\ \sqrt{2} x_1 x_2 \\ x_2^2 \end{pmatrix},
        \begin{pmatrix}y_1^2 \\ \sqrt{2} y_1 y_2 \\ y_2^2 \end{pmatrix} \rangle{} \\
    & = x_1^2 y_1^2 + 2 x_1 y_1 x_2 y_2 + x_2^2 y_2^2  \\
\end{align}
As both results are the same, $\phi$ and $\R^3$ are possible choices for feature map
and feature space.

\subsection*{b)}
We are not sure what an explicit description of an image is, so we gave a mathematical description of the image set. 
\subsubsection*{i}
\begin{gather*}
\left\{ \left( \begin{array}{c}cos^2 \Theta \\ \sqrt{2} cos(\Theta) sin(\Theta) \\ sin^2 \Theta \end{array} \right); \ \Theta \in [0, 2\pi] \right\}
\end{gather*}
\subsubsection*{ii}
\begin{gather*}
\left\{ \left( \begin{array}{c}t^2 \\ \sqrt{2} t s \\ s^2 \end{array} \right); \ t,s \in \R \right\} 
\end{gather*}
\subsection*{c)}
We take 3 linear independent points from our image in b) i:
$\left( \begin{array}{c}1 \\ 0 \\ 0 \end{array} \right), \left( \begin{array}{c}0 \\ 0 \\ 1 \end{array} \right), \left( \begin{array}{c} \frac{1}{2} \\ \frac{\sqrt{2}}{2} \\ \frac{1}{2} \end{array} \right)$ 
With this we can describe the plane parametrically as $\left\{ \left( \begin{array}{c}1 \\ 0 \\ 0 \end{array} \right) + r \cdot \left( \begin{array}{c}-1 \\ 0 \\ 1 \end{array} \right) + s \cdot \left( \begin{array}{c} - \frac{1}{2} \\ \frac{\sqrt{2}}{2} \\ \frac{1}{2} \end{array} \right) ;\ r,s \in \R \right\}$  
\subsection*{d)}
$\left( \begin{array}{c}-1 \\ 0 \\0 \end{array} \right)$ is not in $\varphi (A)$, since $t^2$ can not take negative values for $t \in \R$
\end{document}


\end{document}
